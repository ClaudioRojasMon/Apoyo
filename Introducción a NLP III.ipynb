{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238d7c81-52dd-44e1-8070-06d695eb854f",
   "metadata": {},
   "source": [
    "# Procesamiento Lenguaje Natural (NLP) II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07b7a7-0fe3-44ad-b8e1-8445086fa8d2",
   "metadata": {},
   "source": [
    "## Representación o Vectorización del Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9f3f4-eb35-4a14-83b0-74bbfb2251e1",
   "metadata": {},
   "source": [
    "```{admonition} ¿Qué es la Representación del texto?\n",
    "<div align=\"justify\">La representación del texto implica convertir el texto en un vector numérico para que los algoritmos de Machine Learning puedan entender sus atributos. En Procesamiento del Lenguaje Natural (PLN), este proceso se conoce como Representación de Texto o Vectorización de Texto. La vectorización es el proceso de convertir datos textuales o categóricos en vectores numéricos. Al convertir los datos en formatos numéricos, se puede entrenar el modelo con mayor precisión.</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487c0c5-8810-4b4c-bf31-57c760785ac8",
   "metadata": {},
   "source": [
    "<div align=\"justify\">¿Por qué necesitamos representar las palabras como vectores numéricos?</div> \n",
    "\n",
    "- <div align=\"justify\">Para cuantificar la semántica de las palabras.</div>\n",
    "- <div align=\"justify\">Para capturar su significado contextualizado. Hay palabras que, fuera de su contexto, pueden tener significados completamente diferentes.</div>\n",
    "- <div align=\"justify\">Porque los modelos no pueden procesar texto directamente.</div>\n",
    "\n",
    "\n",
    "<div align=\"justify\">Queremos una representación que capture el significado de una palabra de manera similar a como lo haría una persona. Es importante definir cuál es la unidad básica que queremos analizar: pueden ser palabras, frases dentro de un párrafo o párrafos dentro de un documento. Podemos, por ejemplo, representar una frase como un único vector numérico.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a44a81-035b-472d-ac0a-6c5f8a411579",
   "metadata": {},
   "source": [
    "```{admonition} Para Profundizar \n",
    ":class: tip, dropdown\n",
    "- [De Texto a Vectores](https://www.tacosdedatos.com/ioexception/de-texto-a-vectores-22jd)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb27b8-9c27-47e5-92b5-84cb6e830420",
   "metadata": {},
   "source": [
    "### Término de Frecuencia (Term Frequency – Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87ed66-5087-43a7-b2da-9669dd883698",
   "metadata": {},
   "source": [
    "```{admonition} ¿Qué significa el Término de Frecuencia(TF-IDF)?\n",
    "<div align=\"justify\"> <strong>TF-IDF</strong>< puede definirse como el cálculo de cuán relevante es una palabra en una serie o corpus respecto a un texto. La relevancia aumenta proporcionalmente al número de veces que una palabra aparece en el texto, pero se compensa por la frecuencia de la palabra en el corpus (conjunto de datos).</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af452009-567e-408b-97d5-1e99f8f0f945",
   "metadata": {},
   "source": [
    "#### Ejemplo para explicar TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d9aea-1845-49b0-8510-eaff2e0ea245",
   "metadata": {},
   "source": [
    "<div align=\"justify\">En este ejemplo, calculamos primero la frecuencia de cada término en cada documento (TF), luego la frecuencia de documento inversa (IDF) para cada término y finalmente multiplicamos TF por IDF para obtener los valores de TF-IDF. Esto nos da una medida más equilibrada de la importancia de cada término en cada documento, considerando tanto la frecuencia del término en el documento como su rareza en el corpus total.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab21df3-eb91-41e8-861e-1c6dce09e269",
   "metadata": {},
   "source": [
    "Supongamos que tenemos los siguientes tres documentos:\n",
    "\n",
    "- Documento 1: \"Me gusta caminar por el bosque\"\n",
    "- Documento 2: \"Caminar por el bosque es sanador\"\n",
    "- Documento 3: \"Me gusta el bosque\"\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 1:</strong> Calcular la Frecuencia de Término (TF)</div>\n",
    "\n",
    "| Término       | Documento 1                 | Documento 2                 | Documento 3                 |\n",
    "|---------------|-----------------------------|-----------------------------|-----------------------------|\n",
    "| \"Me\"          | 1/5 = 0.2                   | 0                           | 1/4 = 0.25                  |\n",
    "| \"gusta\"       | 1/5 = 0.2                   | 0                           | 0                           |\n",
    "| \"caminar\"     | 1/5 = 0.2                   | 1/5 = 0.2                   | 0                           |\n",
    "| \"por\"         | 1/5 = 0.2                   | 1/5 = 0.2                   | 0                           |\n",
    "| \"el\"          | 0                           | 0                           | 1/4 = 0.25                  |\n",
    "| \"bosque\"      | 1/5 = 0.2                   | 1/5 = 0.2                   | 1/4 = 0.25                  |\n",
    "| \"es\"          | 0                           | 1/5 = 0.2                   | 0                           |\n",
    "| \"sanador\"     | 0                           | 1/5 = 0.2                   | 0                           |\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 2:</strong> Calcular la Frecuencia de Documento Inversa (IDF)</div>\n",
    "\n",
    "- N = 3 (número total de documentos)\n",
    "\n",
    "| Término       | IDF                          |\n",
    "|---------------|------------------------------|\n",
    "| \"Me\"          | \\(\\log(3/2) \\approx 0.176\\)  |\n",
    "| \"gusta\"       | \\(\\log(3/2) \\approx 0.176\\)  |\n",
    "| \"caminar\"     | \\(\\log(3/2) \\approx 0.176\\)  |\n",
    "| \"por\"         | \\(\\log(3/2) \\approx 0.176\\)  |\n",
    "| \"el\"          | \\(\\log(3/1) = \\log(3) \\approx 0.477\\)  |\n",
    "| \"bosque\"      | \\(\\log(3/2) \\approx 0.176\\)  |\n",
    "| \"es\"          | \\(\\log(3/1) = \\log(3) \\approx 0.477\\)  |\n",
    "| \"sanador\"     | \\(\\log(3/1) = \\log(3) \\approx 0.477\\)  |\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 3:</strong> Calcular TF-IDF</div>\n",
    "\n",
    "| Término       | Documento 1                                       | Documento 2                                       | Documento 3                                       |\n",
    "|---------------|---------------------------------------------------|---------------------------------------------------|---------------------------------------------------|\n",
    "| \"Me\"          | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0 \\cdot 0.176 = 0\\)                             | \\(0.25 \\cdot 0.176 \\approx 0.044\\)                 |\n",
    "| \"gusta\"       | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0 \\cdot 0.176 = 0\\)                             | \\(0 \\cdot 0 = 0\\)                                 |\n",
    "| \"caminar\"     | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0 \\cdot 0 = 0\\)                                 |\n",
    "| \"por\"         | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0 \\cdot 0 = 0\\)                                 |\n",
    "| \"el\"          | \\(0 \\cdot 0.477 = 0\\)                             | \\(0 \\cdot 0.477 = 0\\)                             | \\(0.25 \\cdot 0.477 \\approx 0.119\\)                |\n",
    "| \"bosque\"      | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0.2 \\cdot 0.176 \\approx 0.035\\)                 | \\(0.25 \\cdot 0.176 \\approx 0.044\\)                 |\n",
    "| \"es\"          | \\(0 \\cdot 0.477 = 0\\)                             | \\(0.2 \\cdot 0.477 \\approx 0.095\\)                 | \\(0 \\cdot 0 = 0\\)                                 |\n",
    "| \"sanador\"     | \\(0 \\cdot 0.477 = 0\\)                             | \\(0.2 \\cdot 0.477 \\approx 0.095\\)                 | \\(0 \\cdot 0 = 0\\)                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8007bec-cf87-4d3b-b621-0c34e742b1dd",
   "metadata": {},
   "source": [
    "#### Ejemplo de código para explicar TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958fede-2d76-40d0-abe9-2f576d38ec91",
   "metadata": {},
   "source": [
    "<div align=\"justify\">El código que se presenta a continuación realiza lo siguiente:</div>\n",
    "\n",
    "- <div align=\"justify\"><strong>Tokenización y conteo de palabras</strong>: Divide cada documento en palabras y cuenta la frecuencia de cada término en cada documento.</div>\n",
    "- <div align=\"justify\"><strong>Calcular TF (Frecuencia de Término)</strong>: Calcula la frecuencia de cada término en cada documento.</div>\n",
    "- <div align=\"justify\"><strong>Calcular IDF (Frecuencia de Documento Inversa)</strong>: Calcula la frecuencia inversa de los documentos para cada término.</div>\n",
    "- <div align=\"justify\"><strong>Calcular TF-IDF</strong>: Multiplica los valores de TF por los valores de IDF para obtener los valores de TF-IDF.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eb4dd38-8f6b-472c-b56c-8f449753b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF:\n",
      "Documento 1: {'me': 0.16666666666666666, 'gusta': 0.16666666666666666, 'caminar': 0.16666666666666666, 'por': 0.16666666666666666, 'el': 0.16666666666666666, 'bosque': 0.16666666666666666}\n",
      "Documento 2: {'caminar': 0.16666666666666666, 'por': 0.16666666666666666, 'el': 0.16666666666666666, 'bosque': 0.16666666666666666, 'es': 0.16666666666666666, 'sanador': 0.16666666666666666}\n",
      "Documento 3: {'me': 0.25, 'gusta': 0.25, 'el': 0.25, 'bosque': 0.25}\n",
      "\n",
      "IDF:\n",
      "{'por': 0.4054651081081644, 'gusta': 0.4054651081081644, 'caminar': 0.4054651081081644, 'el': 0.0, 'es': 1.0986122886681098, 'sanador': 1.0986122886681098, 'me': 0.4054651081081644, 'bosque': 0.0}\n",
      "\n",
      "TF-IDF:\n",
      "Documento 1: {'me': 0.06757751801802739, 'gusta': 0.06757751801802739, 'caminar': 0.06757751801802739, 'por': 0.06757751801802739, 'el': 0.0, 'bosque': 0.0}\n",
      "Documento 2: {'caminar': 0.06757751801802739, 'por': 0.06757751801802739, 'el': 0.0, 'bosque': 0.0, 'es': 0.1831020481113516, 'sanador': 0.1831020481113516}\n",
      "Documento 3: {'me': 0.1013662770270411, 'gusta': 0.1013662770270411, 'el': 0.0, 'bosque': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# Documentos de ejemplo\n",
    "doc1 = \"Me gusta caminar por el bosque\"\n",
    "doc2 = \"Caminar por el bosque es sanador\"\n",
    "doc3 = \"Me gusta el bosque\"\n",
    "\n",
    "# Lista de documentos\n",
    "docs = [doc1, doc2, doc3]\n",
    "\n",
    "# Tokenización y conteo de palabras\n",
    "tokenized_docs = [doc.lower().split() for doc in docs]\n",
    "term_counts = [Counter(doc) for doc in tokenized_docs]\n",
    "\n",
    "# Calcular TF (Frecuencia de Término)\n",
    "def compute_tf(term_counts):\n",
    "    tfs = []\n",
    "    for doc_counts in term_counts:\n",
    "        doc_len = sum(doc_counts.values())\n",
    "        tf = {term: count / doc_len for term, count in doc_counts.items()}\n",
    "        tfs.append(tf)\n",
    "    return tfs\n",
    "\n",
    "# Calcular IDF (Frecuencia de Documento Inversa)\n",
    "def compute_idf(term_counts):\n",
    "    N = len(term_counts)\n",
    "    all_terms = set(term for doc_counts in term_counts for term in doc_counts)\n",
    "    idf = {}\n",
    "    for term in all_terms:\n",
    "        doc_freq = sum(1 for doc_counts in term_counts if term in doc_counts)\n",
    "        idf[term] = math.log(N / doc_freq)\n",
    "    return idf\n",
    "\n",
    "# Calcular TF-IDF\n",
    "def compute_tfidf(tfs, idf):\n",
    "    tfidf = []\n",
    "    for tf in tfs:\n",
    "        tfidf_doc = {term: tf_val * idf[term] for term, tf_val in tf.items()}\n",
    "        tfidf.append(tfidf_doc)\n",
    "    return tfidf\n",
    "\n",
    "# Ejecutar las funciones\n",
    "tfs = compute_tf(term_counts)\n",
    "idf = compute_idf(term_counts)\n",
    "tfidf = compute_tfidf(tfs, idf)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"TF:\")\n",
    "for i, tf in enumerate(tfs):\n",
    "    print(f\"Documento {i+1}: {tf}\")\n",
    "\n",
    "print(\"\\nIDF:\")\n",
    "print(idf)\n",
    "\n",
    "print(\"\\nTF-IDF:\")\n",
    "for i, tfidf_doc in enumerate(tfidf):\n",
    "    print(f\"Documento {i+1}: {tfidf_doc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92ec87-4dca-433c-b62b-d55571fbcb63",
   "metadata": {},
   "source": [
    "### One-hot-encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6911129-cebb-4f8a-91b3-af0d1c5692e6",
   "metadata": {},
   "source": [
    "```{admonition} ¿Qué significa One-hot-encoding?\n",
    "<div align=\"justify\">En la <strong>codificación one-hot</strong><, cada palabra se representa como un vector binario donde solo un bit está configurado en 1 (encendido), y todos los demás están en 0 (apagado). La longitud del vector es igual al tamaño del vocabulario, y cada palabra tiene un índice único en este vector. Este método es simple e intuitivo, pero no captura ninguna relación semántica entre las palabras. Se utiliza comúnmente como una representación básica en modelos de aprendizaje automático.</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0be23-0565-43b2-9b88-f73d8a006608",
   "metadata": {},
   "source": [
    "#### Ejemplo para explicar One-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8559e0-1a4c-4942-8f50-75c889135496",
   "metadata": {},
   "source": [
    "<div align=\"justify\">Esta representación muestra cómo cada palabra se convierte en un vector binario único. Sin embargo, como se mencionó, esta técnica no captura ninguna relación semántica entre las palabras.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc32de5b-591e-436d-9d56-a255c1621e8f",
   "metadata": {},
   "source": [
    "<div align=\"justify\">Supongamos que tenemos los siguientes dos documentos:</div>\n",
    "\n",
    "- <div align=\"justify\">Documento 1: \"Me gusta caminar por el bosque\"</div>\n",
    "- <div align=\"justify\">Documento 2: \"Caminar por el bosque es sanador\"</div>\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 1:</strong> Creamos un vocabulario a partir de todas las palabras únicas en ambos documentos:</div>\n",
    "\n",
    "\n",
    "- <div align=\"justify\">Vocabulario: [\"Me\", \"gusta\", \"caminar\", \"por\", \"el\", \"bosque\", \"es\", \"sanador\"]</div>\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 2:</strong> representamos cada palabra como un vector binario en el que solo un bit está configurado en 1 y todos los demás en 0. Cada palabra tiene un índice único en este vector.</div>\n",
    "\n",
    "Vocabulario y sus vectores one-hot:\n",
    "\n",
    "- \"Me\": [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "- \"gusta\": [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "- \"caminar\": [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "- \"por\": [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "- \"el\": [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "- \"bosque\": [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "- \"es\": [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "- \"sanador\": [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 2:</strong>: Para representar los documentos usando la codificación one-hot, cada palabra en el documento se sustituye por su vector one-hot correspondiente.</div><br>\n",
    "<div align=\"justify\">Representación one-hot Documento 1: \"Me gusta caminar por el bosque\"</div>\n",
    "\n",
    "  - \"Me\": [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "  - \"gusta\": [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "  - \"caminar\": [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "  - \"por\": [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "  - \"el\": [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "  - \"bosque\": [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "<div align=\"justify\">Representación one-hot Documento 2: \"Caminar por el bosque es sanador\"</div>\n",
    "\n",
    "  - \"caminar\": [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "  - \"por\": [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "  - \"el\": [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "  - \"bosque\": [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "  - \"es\": [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "  - \"sanador\": [0, 0, 0, 0, 0, 0, 0, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59735da-639b-4fc3-b0fc-23b98cc23c93",
   "metadata": {},
   "source": [
    "#### Ejemplo de código para explicar One-hot-encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254945c3-e4a8-43a7-a1a9-e778f184de03",
   "metadata": {},
   "source": [
    "<div align=\"justify\">El código siguiente proporciona una representación one-hot para los documentos dados, donde cada palabra se convierte en un vector binario con un solo bit configurado en 1 y todos los demás en 0, según su índice en el vocabulario.</div>\n",
    "\n",
    "1. <div align=\"justify\"><strong>Documentos de ejemplo</strong>: Se definen dos documentos como cadenas de texto.</div><br>\n",
    "2. <div align=\"justify\"><strong>Crear el vocabulario</strong>:</div>\n",
    "\n",
    "- <div align=\"justify\">Se crea una lista de todas las palabras únicas en los documentos, convertidas a minúsculas y ordenadas alfabéticamente.</div>\n",
    "- <div align=\"justify\">Se crea un diccionario que asigna un índice a cada palabra del vocabulario.</div>\n",
    "\n",
    "3. <div align=\"justify\"><strong>Crear la representación one-hot para cada palabra</strong>: La función one_hot_vector toma una palabra, el tamaño del vocabulario y el diccionario word_to_index como entrada y devuelve un vector one-hot para esa palabra.</div><br>\n",
    "4. <div align=\"justify\"><strong>Representar los documentos usando la codificación one-hot</strong>: La función document_to_one_hot toma un documento, el tamaño del vocabulario y el diccionario word_to_index como entrada y devuelve una lista de vectores one-hot para cada palabra en el documento.</div><br>\n",
    "5. <div align=\"justify\"><strong>Imprimir los resultados</strong>: Se imprimen el vocabulario, los índices de las palabras y la representación one-hot para cada documento.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f8f74-c908-427c-ae6f-5ffbff46d1bc",
   "metadata": {},
   "source": [
    "```{admonition} ¿Qué es defaultdict?\n",
    "<div align=\"justify\">defaultdict es una subclase de dict que proporciona valores por defecto para claves no existentes. Esto significa que, si intentas acceder a una clave que no existe en el diccionario, defaultdict creará automáticamente un valor por defecto utilizando una función que proporcionas cuando creas la instancia del defaultdict.</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1f4cce-eacd-4afa-9d49-839c9ecc6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['bosque', 'caminar', 'el', 'es', 'gusta', 'me', 'por', 'sanador']\n",
      "Índices de las palabras: {'bosque': 0, 'caminar': 1, 'el': 2, 'es': 3, 'gusta': 4, 'me': 5, 'por': 6, 'sanador': 7}\n",
      "\n",
      "Representación one-hot Documento 1:\n",
      "Me: [0, 0, 0, 0, 0, 1, 0, 0]\n",
      "gusta: [0, 0, 0, 0, 1, 0, 0, 0]\n",
      "caminar: [0, 1, 0, 0, 0, 0, 0, 0]\n",
      "por: [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "el: [0, 0, 1, 0, 0, 0, 0, 0]\n",
      "bosque: [1, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Representación one-hot Documento 2:\n",
      "Caminar: [0, 1, 0, 0, 0, 0, 0, 0]\n",
      "por: [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "el: [0, 0, 1, 0, 0, 0, 0, 0]\n",
      "bosque: [1, 0, 0, 0, 0, 0, 0, 0]\n",
      "es: [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "sanador: [0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Documentos de ejemplo\n",
    "doc1 = \"Me gusta caminar por el bosque\"\n",
    "doc2 = \"Caminar por el bosque es sanador\"\n",
    "\n",
    "# Crear una lista de documentos\n",
    "docs = [doc1, doc2]\n",
    "\n",
    "# Paso 1: Crear el vocabulario\n",
    "vocabulario = sorted(set(word.lower() for doc in docs for word in doc.split()))\n",
    "\n",
    "# Crear un diccionario que asigne un índice a cada palabra del vocabulario\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocabulario)}\n",
    "\n",
    "# Paso 2: Crear la representación one-hot para cada palabra\n",
    "def one_hot_vector(word, vocab_size, word_to_index):\n",
    "    vector = [0] * vocab_size\n",
    "    index = word_to_index[word]\n",
    "    vector[index] = 1\n",
    "    return vector\n",
    "\n",
    "# Representar los documentos usando la codificación one-hot\n",
    "def document_to_one_hot(doc, vocab_size, word_to_index):\n",
    "    words = doc.lower().split()\n",
    "    one_hot_vectors = [one_hot_vector(word, vocab_size, word_to_index) for word in words]\n",
    "    return one_hot_vectors\n",
    "\n",
    "# Tamaño del vocabulario\n",
    "vocab_size = len(vocabulario)\n",
    "\n",
    "# Representación one-hot para cada documento\n",
    "one_hot_doc1 = document_to_one_hot(doc1, vocab_size, word_to_index)\n",
    "one_hot_doc2 = document_to_one_hot(doc2, vocab_size, word_to_index)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Vocabulario:\", vocabulario)\n",
    "print(\"Índices de las palabras:\", word_to_index)\n",
    "\n",
    "print(\"\\nRepresentación one-hot Documento 1:\")\n",
    "for word, vector in zip(doc1.split(), one_hot_doc1):\n",
    "    print(f\"{word}: {vector}\")\n",
    "\n",
    "print(\"\\nRepresentación one-hot Documento 2:\")\n",
    "for word, vector in zip(doc2.split(), one_hot_doc2):\n",
    "    print(f\"{word}: {vector}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd38a50-b2f5-4fef-a157-76cb08ea4782",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ebc95-be6c-4279-8724-807e0317de4d",
   "metadata": {},
   "source": [
    "```{admonition} ¿Qué significa Bag of words (BoW)?\n",
    "<div align=\"justify\">En la <strong> Bag Words o Bolsa de Palabras (BoW)</strong> cada documento se representa como un vector donde cada elemento corresponde al conteo de una palabra en el documento. El orden de las palabras se ignora, y solo sus frecuencias importan. Este método preserva más información que la codificación one-hot, pero aún carece de significado semántico y no considera la importancia relativa de las palabras.</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3e420-33c6-4db7-9839-aca282502a49",
   "metadata": {},
   "source": [
    "#### Ejemplo para explicar Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1beb462-1f6c-4701-abef-ad75b8976d70",
   "metadata": {},
   "source": [
    "<div align=\"justify\">En esta representación, se ignora el orden de las palabras y solo se consideran sus frecuencias. Aunque este método preserva más información que la codificación one-hot, no captura las relaciones semánticas entre las palabras ni la importancia relativa de cada una en el contexto. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035d712-5a8f-4134-bbfc-9831df1cb018",
   "metadata": {},
   "source": [
    "<div align=\"justify\">Supongamos que tenemos los siguientes dos documentos:</div>\n",
    "\n",
    "- <div align=\"justify\">Documento 1: \"Me gusta caminar por el bosque\"</div>\n",
    "- <div align=\"justify\">Documento 2: \"Caminar por el bosque es sanador\"</div>\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 1:</strong> creamos un vocabulario a partir de todas las palabras únicas en ambos documentos:</div>\n",
    "\n",
    "- <div align=\"justify\">Vocabulario: [\"Me\", \"gusta\", \"caminar\", \"por\", \"el\", \"bosque\", \"es\", \"sanador\"]</div>\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 2:</strong> representamos cada documento como un vector de conteos basado en este vocabulario.</div>\n",
    "\n",
    "<div align=\"justify\">Para el Documento 1:</div>\n",
    "\n",
    "- \"Me\" aparece 1 vez\n",
    "- \"gusta\" aparece 1 vez\n",
    "- \"caminar\" aparece 1 vez\n",
    "- \"por\" aparece 1 vez\n",
    "- \"el\" aparece 1 vez\n",
    "- \"bosque\" aparece 1 vez\n",
    "- \"es\" aparece 0 veces\n",
    "- \"sanador\" aparece 0 veces\n",
    "\n",
    "<div align=\"justify\">Vector para Documento 1: [1, 1, 1, 1, 1, 1, 0, 0]</div><br>\n",
    "\n",
    "<div align=\"justify\">Para el Documento 2:</div>\n",
    "\n",
    "- \"Me\" aparece 0 vez\n",
    "- \"gusta\" aparece 0 vez\n",
    "- \"caminar\" aparece 1 vez\n",
    "- \"por\" aparece 1 vez\n",
    "- \"el\" aparece 1 vez\n",
    "- \"bosque\" aparece 1 vez\n",
    "- \"es\" aparece 1 vez\n",
    "- \"sanador\" aparece 1 vez\n",
    "\n",
    "<div align=\"justify\">Vector para Documento 2: [0, 0, 1, 1, 1, 1, 1, 1]</div><br>\n",
    "\n",
    "<div align=\"justify\"><strong>Paso 3:</strong> la representación BoW para los documentos sería:</div>\n",
    "\n",
    "- Documento 1: [1, 1, 1, 1, 1, 1, 0, 0]\n",
    "- Documento 2: [0, 0, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae057a99-8c11-4188-9ebb-731c53097b0c",
   "metadata": {},
   "source": [
    "#### Ejemplo de código para explicar Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc92c8-e234-4565-a1c1-a69ea63a130d",
   "metadata": {},
   "source": [
    "<div align=\"justify\">El código siguiente proporciona una representación de Bolsa de Palabras (BoW) para los documentos dados, donde cada documento se convierte en un vector que cuenta la frecuencia de aparición de cada palabra del vocabulario en el documento:</div>\n",
    "\n",
    "1. <div align=\"justify\"><strong>Documentos de ejemplo</strong>: Se definen dos documentos como cadenas de texto.</div><br>\n",
    "2. <div align=\"justify\"><strong>Crear el vocabulario</strong>: Se crea una lista de todas las palabras únicas en los documentos, convertidas a minúsculas y ordenadas alfabéticamente.</div><br>\n",
    "3. <div align=\"justify\"><strong>Vectorizar cada documento</strong>:</div>\n",
    "- <div align=\"justify\">La función `vectorize` toma un documento y el vocabulario como entrada y devuelve un vector de conteos para ese documento.</div>\n",
    "- <div align=\"justify\">Para cada palabra en el vocabulario, cuenta cuántas veces aparece en el documento y construye un vector de estos conteos.</div>\n",
    "\n",
    "4. <div align=\"justify\"><strong>Imprimir la representación BoW</strong>:</div>\n",
    "- <div align=\"justify\">Se imprimen el vocabulario y los vectores de conteos para ambos documentos.</div>\n",
    "- <div align=\"justify\">Se construye y se imprime la representación BoW para los documentos.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1515b4a8-e265-4eca-b249-4755feb0b274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['bosque', 'caminar', 'el', 'es', 'gusta', 'me', 'por', 'sanador']\n",
      "Vector para Documento 1: [1, 1, 1, 0, 1, 1, 1, 0]\n",
      "Vector para Documento 2: [1, 1, 1, 1, 0, 0, 1, 1]\n",
      "\n",
      "Representación BoW:\n",
      "Documento 1: [1, 1, 1, 0, 1, 1, 1, 0]\n",
      "Documento 2: [1, 1, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Documentos de ejemplo\n",
    "doc1 = \"Me gusta caminar por el bosque\"\n",
    "doc2 = \"Caminar por el bosque es sanador\"\n",
    "\n",
    "# Crear una lista de documentos\n",
    "docs = [doc1, doc2]\n",
    "\n",
    "# Paso 1: Crear el vocabulario\n",
    "vocabulario = sorted(set(word.lower() for doc in docs for word in doc.split()))\n",
    "\n",
    "# Paso 2: Representar cada documento como un vector de conteos\n",
    "def vectorize(doc, vocabulario):\n",
    "    vector = [0] * len(vocabulario)\n",
    "    word_count = Counter(doc.lower().split())\n",
    "    for i, word in enumerate(vocabulario):\n",
    "        vector[i] = word_count[word]\n",
    "    return vector\n",
    "\n",
    "# Vectorizar documentos\n",
    "vector_doc1 = vectorize(doc1, vocabulario)\n",
    "vector_doc2 = vectorize(doc2, vocabulario)\n",
    "\n",
    "# Paso 3: Imprimir la representación BoW para los documentos\n",
    "print(\"Vocabulario:\", vocabulario)\n",
    "print(\"Vector para Documento 1:\", vector_doc1)\n",
    "print(\"Vector para Documento 2:\", vector_doc2)\n",
    "\n",
    "# Representación BoW\n",
    "bow_representation = [vector_doc1, vector_doc2]\n",
    "print(\"\\nRepresentación BoW:\")\n",
    "for i, vector in enumerate(bow_representation):\n",
    "    print(f\"Documento {i+1}: {vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c769aa-1e85-433f-bc2e-0a738780c844",
   "metadata": {},
   "source": [
    "`````{admonition} Para tener en cuenta\n",
    ":class: tip\n",
    "<div align=\"justify\">Una bolsa de palabras trata a todas las palabras por igual y sólo se preocupa por la frecuencia de palabras únicas en las frases. El TF-IDF da importancia a las palabras de un documento teniendo en cuenta tanto la frecuencia como la unicidad.</div>\n",
    "`````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d6f4f-257d-43e9-b613-ccef67fddca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
